#!/usr/bin/env python3

# -*- coding: utf-8 -*-

# https://github.com/remino/safaricookies

from io import BytesIO
from struct import unpack
from time import gmtime, strftime
import sys


def parse():
	input_file = sys.stdin.buffer
	file_header = input_file.read(4)
	output_file = sys.stdout
	if file_header == b"cook":
		num_pages = unpack(">i", input_file.read(4))[0]
		page_sizes = [
		    unpack(">i", input_file.read(4))[0] for _ in range(num_pages)
		]
		pages = [input_file.read(ps) for ps in page_sizes]

		output_file.write("# Netscape HTTP Cookie File\n")
		output_file.flush()

		for index, page in enumerate(pages):
			page = BytesIO(page)
			page.read(4)
			num_cookies = unpack("<i", page.read(4))[0]
			cookie_offsets = [
			    unpack("<i", page.read(4))[0] for nc in range(num_cookies)
			]
			page.read(4)

			for offset in cookie_offsets:
				page.seek(offset)
				cookiesize = unpack("<i", page.read(4))[0]
				cookie = BytesIO(page.read(cookiesize))
				cookie.read(4)
				flags = unpack("<i", cookie.read(4))[0]
				if flags == 0:
					secure = False
					cookie_flags = ""
				elif flags == 1:
					secure = True
					cookie_flags = "Secure"
				elif flags == 4:
					cookie_flags = "HttpOnly"
				elif flags == 5:
					secure = True
					cookie_flags = "Secure; HttpOnly"
				else:
					secure = False
					cookie_flags = "Unknown"
				cookie.read(4)  # unused field
				urloffset = unpack("<i", cookie.read(4))[0]
				nameoffset = unpack("<i", cookie.read(4))[0]
				pathoffset = unpack("<i", cookie.read(4))[0]
				valueoffset = unpack("<i", cookie.read(4))[0]
				cookie.read(8)  # unused field
				expiry_date_epoch = unpack("<d", cookie.read(8))[0] + 978307200
				cookie.read(8)  # unused creation time
				expiry_date = strftime("%a, %d %b %Y ",
				                       gmtime(expiry_date_epoch))[:-1]
				expiry_date_epoch = int(expiry_date_epoch)
				cookie.seek(urloffset - 4)
				url = ""
				u = cookie.read(1)
				while unpack("<b", u)[0] != 0:
					url += str(u, encoding="utf-8")
					u = cookie.read(1)
				cookie.seek(nameoffset - 4)
				name = ""
				n = cookie.read(1)
				while unpack("<b", n)[0] != 0:
					name += str(n, encoding="utf-8")
					n = cookie.read(1)
				cookie.seek(pathoffset - 4)
				path = ""
				pa = cookie.read(1)
				while unpack("<b", pa)[0] != 0:
					path += str(pa, encoding="utf-8")
					pa = cookie.read(1)
				cookie.seek(valueoffset - 4)
				value = ""
				va = cookie.read(1)
				while unpack("<b", va)[0] != 0:
					value += str(va, encoding="utf-8")
					va = cookie.read(1)
				if url[0] == ".":
					subdomain = True
				else:
					subdomain = False
				# Output Netscape cookie format
				# domain for-subdomains path secure expiration name value
				cookie_info = f"{url}	{str(subdomain).upper()}	{path}	{str(secure).upper()}	{expiry_date_epoch}	{name}	{value}"
				output_file.write(cookie_info + "\n")
				output_file.flush()
		output_file.close()
		input_file.close()
		return "success"
	else:
		input_file.close()
		raise


def main():
	parse()


if __name__ == '__main__':
	main()
